{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import *\n",
    "\n",
    "import arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.load_dataset\n",
    "import utils.data_loader\n",
    "import utils.metrics\n",
    "from utils.early_stop import EarlyStopping, Stop_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'yahooR3'\n",
    "base_model_args = {'emb_dim': 10, 'learning_rate': 0.01, 'imputaion_lambda': 0.01, 'weight_decay': 1}\n",
    "weight1_model_args ={'learning_rate': 0.1, 'weight_decay': 0.001}\n",
    "weight2_model_args =  {'learning_rate': 1e-3, 'weight_decay': 1e-2}\n",
    "imputation_model_args = {'learning_rate': 1e-1, 'weight_decay': 1e-4}\n",
    "training_args =  {'batch_size': 1024, 'epochs': 100, 'patience': 20, 'block_batch': [1000, 100]}\n",
    "uniform_ratio = 0.05\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_implicit import setup_seed\n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='yahooR3'\n",
    "training_args = {'batch_size': 1024,\n",
    "                 'epochs': 500, \n",
    "                 'patience': 60, \n",
    "                 'block_batch': [6000, 500]}\n",
    "\n",
    "base_model_args = {'emb_dim': 10, \n",
    "                   'learning_rate': 0.0001, \n",
    "                   'imputaion_lambda': 1, \n",
    "                   'weight_decay': 1}\n",
    "weight1_model_args = {'learning_rate': 0.01, 'weight_decay': 0.01}\n",
    "weight2_model_args = {'learning_rate': 1e-3, 'weight_decay': 1e-2}\n",
    "imputation_model_args = {'emb_dim': 10, 'learning_rate': 1e-1, 'weight_decay': 1e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments.parse_args()\n",
    "# para(args)\n",
    "setup_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate implicit feedback data, we also use the aforementioned\n",
    "# datasets, but abandon the negative feedback of the training data.\n",
    "train, unif_train, validation, test = utils.load_dataset.load_dataset(data_name=dataset, type = 'implicit', seed = seed, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15400, 1000]),\n",
       " torch.Size([15400, 1000]),\n",
       " torch.Size([15400, 1000]),\n",
       " torch.Size([15400, 1000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, unif_train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 15399, 15399, 15399],\n",
       "                       [   13,   152,   169,  ...,   563,   636,   948]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "       device='cuda:0', size=(15400, 1000), nnz=125077, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 125077]), torch.Size([125077]), 125077)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train._indices().shape, train._values().shape, train._nnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_implicit import train_and_eval\n",
    "\n",
    "# train_and_eval(train, \n",
    "#                unif_train, \n",
    "#                validation, \n",
    "#                test,\n",
    "#                device,\n",
    "#                base_model_args = base_model_args, \n",
    "#                weight1_model_args = weight1_model_args,\n",
    "#                weight2_model_args = weight2_model_args,\n",
    "#                imputation_model_args = imputation_model_args, \n",
    "#                training_args = training_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Model - AutoDebias_RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, unif_train_data, val_data, test_data = train, unif_train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dense = train_data.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15400, 1000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_unif, items_unif = unif_train_data._indices()[0], unif_train_data._indices()[1]\n",
    "y_unif = unif_train_data._values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = utils.data_loader.Block(train_data, u_batch_size=training_args['block_batch'][0], i_batch_size=training_args['block_batch'][1], device=device)\n",
    "val_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(val_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)\n",
    "test_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(test_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils.data_loader.Block"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLinear(nn.Module):\n",
    "  def __init__(self, n_user, n_item, n):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "    self.data_bias = nn.Embedding(n, 1)\n",
    "    self.init_embedding(0)\n",
    "  \n",
    "  def init_embedding(self, init):\n",
    "    nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.data_bias.weight, mode='fan_out', a = init)\n",
    "    self.data_bias.weight.data *= 0.001\n",
    "    \n",
    "  def forward(self, users, items, values):\n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.user_bias(items)\n",
    "    d_bias = self.user_bias(users)\n",
    "    \n",
    "    preds = u_bias + i_bias + d_bias\n",
    "    return preds.squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape\n",
    "n_user, n_item = train_data.shape\n",
    "\n",
    "# Base model and its optimizer. This optimizer is for optimize parameters in base model using the updated weights (true optimization).\n",
    "base_model = MetaMF(n_user, n_item, dim=base_model_args['emb_dim'], dropout=0).to(device)\n",
    "base_optimizer = torch.optim.SGD(base_model.params(), lr=base_model_args['learning_rate'], weight_decay=0) # todo: other optimizer SGD\n",
    "\n",
    "# Weight model and its optimizer. This optimizer is for optimize parameters of weight model. \n",
    "weight1_model = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "weight1_optimizer = torch.optim.Adam(weight1_model.parameters(), lr=weight1_model_args['learning_rate'], weight_decay=weight1_model_args['weight_decay'])\n",
    "\n",
    "weight2_model = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "weight2_optimizer = torch.optim.Adam(weight2_model.parameters(), lr=weight2_model_args['learning_rate'], weight_decay=weight2_model_args['weight_decay'])\n",
    "\n",
    "imputation_model = OneLinear(3).to(device)\n",
    "imputation_optimizer = torch.optim.Adam(imputation_model.parameters(), lr=imputation_model_args['learning_rate'], weight_decay=imputation_model_args['weight_decay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_criterion\n",
    "sum_criterion = nn.MSELoss(reduction='sum')\n",
    "none_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_weight1_model = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "stable_weight1_model.load_state_dict(torch.load(\"/home/dable/Robust_Deconfounder_master/datasets/yahooR3/propensity_auto/ps1.pth.tar\"))\n",
    "\n",
    "stable_weight2_model = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "stable_weight2_model.load_state_dict(torch.load(\"/home/dable/Robust_Deconfounder_master/datasets/yahooR3/propensity_auto/ps2.pth.tar\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400 1000\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = train_data.shape\n",
    "print(n_user, n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "stopping_args = Stop_args(patience=training_args['patience'], max_epochs=training_args['epochs'])\n",
    "early_stopping = EarlyStopping(base_model, **stopping_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items = next(iter(train_loader.User_loader)), next(iter(train_loader.Item_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9851, 11046,   293,  ..., 13523, 13343, 13636], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(users) # dim: 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 31, 681, 191, 200, 775, 452, 300, 765, 696, 391,  86, 939, 937, 338,\n",
      "        684, 420, 166, 256, 852, 566, 768, 364, 604, 165, 354, 506, 316, 683,\n",
      "        509, 365, 938, 679, 588, 219, 470, 413, 374, 203, 812, 648, 999, 969,\n",
      "          7, 560, 260, 883, 501, 124, 623,  34, 798, 175, 211, 868, 671, 369,\n",
      "        954, 282,  77, 857,  45, 632, 732, 608, 906, 870, 572, 327, 372, 533,\n",
      "        873,  15, 138, 784, 901, 209, 199, 451, 541, 698,  64, 188,   2, 948,\n",
      "        690, 845, 886,  65, 263, 457, 824, 719, 110, 607,  99,  26, 776, 685,\n",
      "        844, 466, 854, 539, 907,  28, 252, 336, 729, 489, 201, 990, 895, 135,\n",
      "        232, 395, 488, 301, 302, 916, 450, 445, 748, 284, 581,  49, 638, 527,\n",
      "        159, 215, 216, 774, 903, 304, 773, 342,  52, 524, 749,  90, 556, 483,\n",
      "        922, 752, 225,  83, 244, 208, 833, 292, 315, 904, 237, 864,  13, 704,\n",
      "        473, 449, 677, 672, 619, 924, 498, 927, 117, 610, 703,  98, 436, 808,\n",
      "         56, 928, 478, 348, 971, 701, 715, 184, 194, 855,   0, 143, 131, 811,\n",
      "        846, 646, 234, 240, 785, 106, 575,   8, 500,  73, 603, 412, 979, 793,\n",
      "        858, 438, 471, 137, 425,  72, 742, 835, 158,  41, 865, 437, 499, 589,\n",
      "        724, 557, 992, 813, 582, 248, 877, 569, 881, 761, 331, 850, 829, 766,\n",
      "        276,  84, 913, 183, 351,  20, 324, 269, 799, 492, 287, 840, 311, 577,\n",
      "        140,  95, 423, 547,  81, 286, 661,  17, 609, 363, 727, 119, 618, 816,\n",
      "        467,  42, 187, 469, 317, 268, 820, 629, 134,  89, 968, 535, 981,  37,\n",
      "        189, 941, 633, 594, 905, 936, 767, 468, 565, 246, 670, 463, 733, 637,\n",
      "        102, 650, 178, 668,  63, 265, 531, 580, 296, 801, 778, 602, 665, 823,\n",
      "        439,  10, 122, 657, 167, 915, 838, 614, 919, 385, 777, 236, 323, 880,\n",
      "        522, 546, 974, 318, 700,  51, 807, 621, 642,  48, 568,   9, 885, 599,\n",
      "        914, 982, 756, 771,   4, 525, 530, 153, 144,  66, 616, 313, 518, 718,\n",
      "         97, 405, 818,  11, 118, 764, 689, 561,  75, 705, 150, 402, 157, 433,\n",
      "        186, 583, 279, 350, 458, 285, 266, 340, 942, 101, 931, 790, 127, 735,\n",
      "        339, 804, 149, 173, 383, 585, 297,  19, 918,  62, 320, 802, 651, 972,\n",
      "        997, 791, 147, 427, 210, 600, 794, 548, 553, 562, 132,  85, 590, 164,\n",
      "        283, 631, 472, 874, 655, 869, 278, 710, 381, 168, 951, 722, 275, 326,\n",
      "        222, 961, 734, 953, 503, 779, 563, 861, 357, 760, 130, 831,  39, 945,\n",
      "        540, 788, 314, 709, 613, 669, 935, 800, 814, 406, 291, 277, 419, 950,\n",
      "        294, 444,  44, 932, 129, 653, 152, 477, 230, 879, 398,  38,  18, 817,\n",
      "         70, 891, 464,  12, 878, 156, 154, 474, 995,   3, 552, 787, 192, 442,\n",
      "        592,  94, 839, 109, 988, 714, 893, 520, 390, 956, 611, 686, 944,  59,\n",
      "        834,  29, 781, 570, 989, 772, 487, 695, 288, 160, 911, 720, 400,  60,\n",
      "        673, 837,  82, 980, 882, 360, 126, 181, 223, 250], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(items) # dim: 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train: all 1's\n",
    "# dim of users_train, items_train ~ 25000 (train._nnz() * 6000 * 500)\n",
    "users_train, items_train, y_train = train_loader.get_batch(users, items, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24661]), torch.Size([24661]), torch.Size([24661]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train.size(), items_train.size(), y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Assumed update of $\\theta$ (update parameters one_step )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weight 1: w_k^{(1)}, only for training data (Eq 17.)\n",
    "weight1_model.train()\n",
    "weight1 = weight1_model(users_train, items_train, (y_train==1)*1)\n",
    "weight2 = torch.exp(torch.nn.ReLU()(weight1/10)) # for stable training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all pair\n",
    "all_pair = torch.cartesian_prod(users, items)\n",
    "users_all, items_all = all_pair[:,0], all_pair[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weight2: w_{ui}^{(2)} (Eq 17.)\n",
    "# ((train_dense[users_all, items_all]!=0)*1): unobserved -> 1, observed -> 0\n",
    "weight2_model.train()\n",
    "weight2 = weight2_model(users_all, items_all, ((train_dense[users_all, items_all]!=0)*1))\n",
    "weight2 = torch.exp(torch.nn.ReLU()(weight2/10)) # for stable training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate imputation values\n",
    "imputation_model.train()\n",
    "impu_all = torch.tanh(imputation_model((train_dense[users_all, items_all]).long()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Assumed Update of theta (Black arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_step_model : assumed model, just update one step on base model. It is for updating parameters\n",
    "one_step_model = MetaMF(n_user, n_item, dim=base_model_args['emb_dim'], dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaMF(\n",
       "  (user_latent): MetaEmbed()\n",
       "  (item_latent): MetaEmbed()\n",
       "  (user_bias): MetaEmbed()\n",
       "  (item_bias): MetaEmbed()\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_step_model.load_state_dict(base_model.state_dict())\n",
    "\n",
    "one_step_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formal parameter: using training set to update parameters\n",
    "# 1) observation data\n",
    "y_hat_obs = one_step_model(users_train, items_train)\n",
    "cost_obs = none_criterion(y_hat_obs, y_train)\n",
    "loss_obs = torch.sum(weight1 * cost_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) all pair data \n",
    "y_hat_all = one_step_model(users_all, items_all)\n",
    "cost_all = none_criterion(y_hat_all, impu_all)\n",
    "loss_all = torch.sum(weight2 * cost_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: \\hat{L}_{T}(f | \\phi)\n",
    "loss = loss_obs + base_model_args['imputaion_lambda'] * loss_all + base_model_args['weight_decay'] * one_step_model.l2_norm(users_all, items_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameters of one_step_model\n",
    "one_step_model.zero_grad()\n",
    "grads = torch.autograd.grad(loss, (one_step_model.params()), create_graph=True)\n",
    "one_step_model.update_params(base_model_args['learning_rate'], source_params=grads)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Update of $\\phi(\\psi)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latter hyper_parameter: using uniform set to update hyper_parameters\n",
    "y_hat_l = one_step_model(users_unif, items_unif)\n",
    "loss_l = sum_criterion(y_hat_l, y_unif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update hyper-parameters\n",
    "weight1_optimizer.zero_grad()\n",
    "weight2_optimizer.zero_grad()\n",
    "imputation_optimizer.zero_grad()\n",
    "\n",
    "loss_l.backward()\n",
    "\n",
    "weight1_optimizer.step()\n",
    "weight2_optimizer.step()\n",
    "imputation_optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1_model_ad = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "weight2_model_ad = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "imputation_model_ad = OneLinear(3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the weights of coresponding non-adversarial model\n",
    "weight1_model_ad.load_state_dict(weight1_model.state_dict())\n",
    "weight2_model_ad.load_state_dict(weight2_model.state_dict())\n",
    "imputation_model_ad.load_state_dict(imputation_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1_model_ad.train()\n",
    "weight1_ad = weight1_model_ad(users_train, items_train, (y_train==1)*2)\n",
    "weight1_ad = torch.exp(torch.nn.ReLU()(weight1_ad/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2_model_ad.train()\n",
    "weight2_ad = weight2_model_ad(users_all, items_all,(train_dense[users_all,items_all]!=0)*1)\n",
    "weight2_ad = torch.exp(torch.nn.ReLU()(weight2_ad/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_model_ad.train()\n",
    "impu_ad_all = torch.tanh(imputation_model_ad((train_dense[users_all,items_all]).long()+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_step_model_ad = MetaMF(n_user, n_item, dim=base_model_args['emb_dim'], dropout=0)\n",
    "one_step_model_ad.load_state_dict(base_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model_ad.train()\n",
    "\n",
    "# observation data\n",
    "y_hat_ad_obs = one_step_model_ad(users_train, items_train)\n",
    "cost_ad_obs = none_criterion(y_hat_ad_obs, y_train)\n",
    "loss_ad_obs = torch.sum(cost_ad_obs * weight1_ad)\n",
    "\n",
    "# all pair data in this block\n",
    "y_hat_ad_all = one_step_model_ad(users_all, items_all)\n",
    "cost_ad_all = none_criterion(y_hat_ad_all, impu_ad_all)\n",
    "loss_ad_all = torch.sum(cost_ad_all * weight2_ad)\n",
    "\n",
    "loss_ad = loss_ad_obs + base_model_args['imputaion_lambda'] * loss_ad_all + base_model_args['weight_decay'] * one_step_model_ad.l2_norm(users_all, items_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameters of one_step_model\n",
    "one_step_model_ad.zero_grad()\n",
    "grads = torch.autograd.grad(loss_ad, (one_step_model_ad.params()), create_graph=True)\n",
    "one_step_model_ad.update_params(base_model_args['learning_rate'], source_params=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial learning on biased data\n",
    "y_hat_ad = one_step_model_ad(users_train, items_train)\n",
    "loss_ad = -1 * sum_criterion(y_hat_ad, y_train) # -1: min -f = max f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-28298.2051, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversal update hyper-parameters\n",
    "weight1_ad_optimizer = torch.optim.SGD(weight1_model_ad.parameters(), lr=0.1, weight_decay=0)\n",
    "weight2_ad_optimizer = torch.optim.SGD(weight2_model_ad.parameters(), lr=0.1, weight_decay=0)\n",
    "weight1_ad_optimizer.zero_grad()\n",
    "weight2_ad_optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ad.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1_ad_optimizer.step()\n",
    "weight2_ad_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1_after_adv = weight1_model_ad(users_train, items_train,(y_train==1)*1)\n",
    "weight1_after_adv = torch.exp(torch.nn.ReLU()(weight1_after_adv / 10))\n",
    "\n",
    "weight2_after_adv = weight2_model_ad(users_all, items_all,(train_dense[users_all,items_all]!=0)*1)\n",
    "weight2_after_adv = torch.exp(torch.nn.ReLU()(weight2_after_adv / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_bound(Gamma_Auto, ips_adv, ips_hat):\n",
    "  upbound = torch.ones_like(ips_hat) + (ips_hat - torch.ones_like(ips_hat)) / Gamma_Auto\n",
    "  lowbound = torch.ones_like(ips_hat) + (ips_hat - torch.ones_like(ips_hat)) * Gamma_Auto\n",
    "  \n",
    "  print(f'lowbound: {lowbound}')\n",
    "  print(f'upbound: {upbound}')\n",
    "  print(f'comparison: {upbound > lowbound}')\n",
    "  \n",
    "  # over_up_mask: upbound 보다 크면 1, 아니면 0\n",
    "  # over_low_mask: lowbound 보다 작으면 1, 아니면 0\n",
    "  over_up_mask = torch.where(ips_adv>upbound, torch.ones_like(ips_hat), torch.zeros_like(ips_hat))\n",
    "  over_low_mask = torch.where(ips_adv<lowbound, torch.ones_like(ips_hat), torch.zeros_like(ips_hat))\n",
    "  \n",
    "  print(f'over_up_mask: {over_up_mask}')\n",
    "  print(f'over_low_mask: {over_low_mask}')\n",
    "  \n",
    "  # torch.ones_like(ips_hat) - over_up_mask - over_low_mask: if two masking conditions are not satisfied, set 1 which means we will use ips_adv\n",
    "  return over_up_mask*upbound + over_low_mask*lowbound + (torch.ones_like(ips_hat) - over_up_mask - over_low_mask) * ips_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowbound: tensor([1.0809, 1.0000, 1.0000,  ..., 1.0128, 1.0128, 1.0000], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "upbound: tensor([1.0090, 1.0000, 1.0000,  ..., 1.0014, 1.0014, 1.0000], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "comparison: tensor([False, False, False,  ..., False, False, False], device='cuda:0')\n",
      "over_up_mask: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "over_low_mask: tensor([1., 0., 0.,  ..., 1., 1., 0.], device='cuda:0')\n",
      "lowbound: tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "upbound: tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "comparison: tensor([False, False, False,  ..., False, False, False], device='cuda:0')\n",
      "over_up_mask: tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')\n",
      "over_low_mask: tensor([0., 1., 0.,  ..., 0., 0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# inner bound\n",
    "ancor_1 = stable_weight1_model(users_train, items_train, (y_train==1)*1)\n",
    "ancor_1 = torch.exp(torch.nn.ReLU()(ancor_1 / 10))\n",
    "ancor_2 = stable_weight2_model(users_all, items_all, (train_dense[users_all,items_all]!=0)*1)\n",
    "ancor_2 = torch.exp(torch.nn.ReLU()(ancor_2 / 10))\n",
    "\n",
    "weight1 = inner_bound(3, weight1_after_adv, ancor_1)\n",
    "weight2 = inner_bound(3, weight2_after_adv, ancor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impu_all = torch.tanh(imputation_model((train_dense[users_all,items_all]).long()+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Update of $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss of training set\n",
    "base_model.train()\n",
    "# all pair\n",
    "y_hat_all = base_model(users_all, items_all)\n",
    "cost_all = none_criterion(y_hat_all, impu_all)\n",
    "loss_all = torch.sum(cost_all * weight2)\n",
    "# observation\n",
    "y_hat_obs = base_model(users_train, items_train)\n",
    "cost_obs = none_criterion(y_hat_obs, y_train)\n",
    "loss_obs = torch.sum(cost_obs * weight1)\n",
    "loss = loss_obs + base_model_args['imputaion_lambda'] * loss_all + base_model_args['weight_decay'] * base_model.l2_norm(users_all, items_all)\n",
    "\n",
    "base_optimizer.zero_grad()\n",
    "loss.backward()\n",
    "base_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.eval()\n",
    "with torch.no_grad():\n",
    "    # training metrics\n",
    "    train_pre_ratings = torch.empty(0).to(device)\n",
    "    train_ratings = torch.empty(0).to(device)\n",
    "    for u_batch_idx, users in enumerate(train_loader.User_loader): \n",
    "        for i_batch_idx, items in enumerate(train_loader.Item_loader): \n",
    "            users_train, items_train, y_train = train_loader.get_batch(users, items, device)\n",
    "            pre_ratings = base_model(users_train, items_train)\n",
    "            train_pre_ratings = torch.cat((train_pre_ratings, pre_ratings))\n",
    "            train_ratings = torch.cat((train_ratings, y_train))\n",
    "\n",
    "    # validation metrics\n",
    "    val_pre_ratings = torch.empty(0).to(device)\n",
    "    val_ratings = torch.empty(0).to(device)\n",
    "    for batch_idx, (users, items, ratings) in enumerate(val_loader):\n",
    "        pre_ratings = base_model(users, items)\n",
    "        val_pre_ratings = torch.cat((val_pre_ratings, pre_ratings))\n",
    "        val_ratings = torch.cat((val_ratings, ratings))\n",
    "\n",
    "train_results = utils.metrics.evaluate(train_pre_ratings, train_ratings, ['MSE'], device)\n",
    "val_results = utils.metrics.evaluate(val_pre_ratings, val_ratings, ['MSE', 'NLL', 'AUC'], device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(early_stopping.max_epochs):\n",
    "    for u_batch_idx, users in enumerate(train_loader.User_loader):\n",
    "        for i_batch_idx, items in enumerate(train_loader.Item_loader):\n",
    "            # observation data in this batch\n",
    "            users_train, items_train, y_train = train_loader.get_batch(users, items, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_eval(train, \n",
    "#               unif_train,\n",
    "#               validation,\n",
    "#               test,\n",
    "#               device, \n",
    "#               base_model_args=base_model_args, \n",
    "#               weight1_model_args=weight1_model_args, \n",
    "#               weight2_model_args=weight2_model_args, \n",
    "#               imputation_model_args=imputation_model_args, \n",
    "#               training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform sparse to dense matrix\n",
    "train_data = train\n",
    "train_dense = train_data.to_dense()\n",
    "train_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif_train_data = unif_train\n",
    "users_unif = unif_train_data._indices()[0]\n",
    "items_unif = unif_train_data._indices()[1]\n",
    "y_unif = unif_train_data._values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data_loader. (block matrix data loader)\n",
    "\n",
    "train_loader = utils.data_loader.Block(train_data,\n",
    "                                       u_batch_size=training_args['block_batch'][0],\n",
    "                                       i_batch_size=training_args['block_batch'][1],\n",
    "                                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, test_data = validation, test\n",
    "val_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(val_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)\n",
    "test_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(test_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400 1000\n"
     ]
    }
   ],
   "source": [
    "# data shape\n",
    "n_user, n_item = train_data.shape\n",
    "print(n_user, n_item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "  \"\"\"\n",
    "  Base module for matrix factoriazation\n",
    "  \"\"\"\n",
    "  def __init__(self, n_user, n_item, dim=40, dropout=0, init=None):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_latent = nn.Embedding(n_user, dim)\n",
    "    self.item_latent = nn.Embedding(n_item, dim)\n",
    "    \n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "    \n",
    "    self.dropout_p = dropout\n",
    "    self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "    if not init:\n",
    "      self.init_embedding(init)\n",
    "    else:\n",
    "      self.init_embedding(0)\n",
    "    \n",
    "  def init_embedding(self, init):\n",
    "    nn.init.kaiming_normal_(self.user_latent.weight.data, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.item_latent.weight.data, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.user_bias.weight.data, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight.data, mode='fan_out', a=init)\n",
    "    \n",
    "  def forward(self, users, items):\n",
    "    u_latent = self.dropout(self.user_latent(users))\n",
    "    i_latent = self.dropout(self.item_latent(items))\n",
    "    \n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.user_bias(items)\n",
    "    \n",
    "    preds = torch.sum(u_latent * i_latent, dim=1, keepdim=True) + u_bias + i_bias\n",
    "    \n",
    "    return preds.squeeze(dim=-1)\n",
    "  \n",
    "  def l2_norm(self, users, items):\n",
    "    users = torch.unique(users)\n",
    "    items = torch.unique(items)\n",
    "    \n",
    "    l2_loss = (torch.sum(self.user_latent(users)**2) + torch.sum(self.item_latent(items)**2)) / 2\n",
    "    return l2_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MetaModule, MetaEmbed\n",
    "class MetaEmbed(MetaModule):\n",
    "  \"\"\"\n",
    "  Base module for matrix factorization\n",
    "  \"\"\"\n",
    "  def __init__(self, dim_1, dim_2):\n",
    "    super().__init__()\n",
    "    ignore = nn.Embedding(dim_1, dim_2)\n",
    "    \n",
    "    self.register_buffer('weight', to_var(ignore.weight.data, requires_grad=True))\n",
    "    self.register_buffer('bias', None)\n",
    "    \n",
    "  def forward(self):\n",
    "    return self.weight\n",
    "  \n",
    "  def named_leaves(self):\n",
    "    return [('weight', self.weight), ('bias', self.bias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaMF(MetaModule):\n",
    "    \"\"\"\n",
    "    Base module for matrix factorization.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_user, n_item, dim=40, dropout=0, init = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_latent = MetaEmbed(n_user, dim)\n",
    "        self.item_latent = MetaEmbed(n_item, dim)\n",
    "        self.user_bias = MetaEmbed(n_user, 1)\n",
    "        self.item_bias = MetaEmbed(n_item, 1)\n",
    "        self.dropout_p = dropout\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        if init is not None:\n",
    "            self.init_embedding(init)\n",
    "        else: \n",
    "            self.init_embedding(0)\n",
    "        \n",
    "    def init_embedding(self, init): \n",
    "\n",
    "        nn.init.kaiming_normal_(self.user_latent.weight, mode='fan_out', a = init)\n",
    "        nn.init.kaiming_normal_(self.item_latent.weight, mode='fan_out', a = init)\n",
    "        nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a = init)\n",
    "        nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a = init)\n",
    "          \n",
    "    def forward(self, users, items):\n",
    "        u_latent = self.dropout(self.user_latent.weight[users])\n",
    "        i_latent = self.dropout(self.item_latent.weight[items])\n",
    "        u_bias = self.user_bias.weight[users]\n",
    "        i_bias = self.item_bias.weight[items]\n",
    "\n",
    "        preds = torch.sum(u_latent * i_latent, dim=1, keepdim=True) + u_bias + i_bias\n",
    "        return preds.squeeze(dim=-1)\n",
    "\n",
    "    def l2_norm(self, users, items, unique = True): \n",
    "\n",
    "        users = torch.unique(users)\n",
    "        items = torch.unique(items)\n",
    "        \n",
    "        l2_loss = (torch.sum(self.user_latent.weight[users]**2) + torch.sum(self.item_latent.weight[items]**2)) / 2\n",
    "        return l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Define the embedding layer\n",
    "# embedding_dim = 10\n",
    "# vocab_size = 100\n",
    "# embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# # Example input indices\n",
    "# indices = torch.tensor(list(range(4)))\n",
    "\n",
    "# # Apply the embedding layer\n",
    "# embedded_output = embedding_layer(indices)\n",
    "\n",
    "# print(embedded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MetaMF(n_user, n_item, dim=base_model_args['emb_dim'], dropout=0).to(device)\n",
    "base_optimizer = torch.optim.SGD(base_model.params(), lr=base_model_args['learning_rate'], weight_decay=0) # todo: other optimizer SGD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "register_buffer 로 layer를 등록하면 어떤 특징이 있는가?\n",
    "\n",
    "1. optimizer가 업데이트하지 않는다.\n",
    "\n",
    "2. 그러나 값은 존재한다(하나의 layer로써 작용한다고 보면 된다.)\n",
    "\n",
    "3. state_dict()로 확인이 가능하다.\n",
    "\n",
    "4. GPU연산이 가능하다.\n",
    "\n",
    " \n",
    "\n",
    "따라서 네트워크를 구성함에 있어서 네트워크를 end2end로 학습시키고 싶은데 중간에 업데이트를 하지않는 일반 layer를 넣고 싶을 때 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x, requires_grad=True):\n",
    "  x = x.cuda() if torch.cuda.is_available() else x\n",
    "  return Variable(x, requires_grad=requires_grad) # 현재는 모든 tensor에서 required_grad 옵션을 통해 gradient를 추적할 수 있기 때문에 따로 위와 같이 Variable로 감싸줄 필요가 없다. (현재는 쓸 필요 없음)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLinear(nn.Module):\n",
    "  \"\"\"\n",
    "  linear model: r\n",
    "  \"\"\"\n",
    "  def __init__(self, n):\n",
    "    super().__init__()\n",
    "\n",
    "    self.bias = nn.Embedding(n,1)\n",
    "    self.init_embedding()\n",
    "\n",
    "  def init_embedding(self):\n",
    "    self.bias.weight.data *= 0.01\n",
    "\n",
    "  def forward(self, values):\n",
    "    d_bias = self.bias(values)\n",
    "    return d_bias.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLinear(nn.Module):\n",
    "  def __init__(self, n_user, n_item):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "\n",
    "    self.init_embedding(0)\n",
    "  \n",
    "  def init_embedding(self, init):\n",
    "    nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a=init)\n",
    "\n",
    "  def forward(self, users, items):\n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.item_bias(items)\n",
    "    preds = u_bias + i_bias\n",
    "    \n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLinear(nn.Module):\n",
    "  \"\"\"\n",
    "  linear model: u + i + r / o\n",
    "  \"\"\"\n",
    "  def __init__(self, n_user, n_item, n):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "    self.data_bias= nn.Embedding(n, 1)\n",
    "    self.init_embedding(0)\n",
    "      \n",
    "  def init_embedding(self, init): \n",
    "    nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.data_bias.weight, mode='fan_out', a = init)\n",
    "    self.data_bias.weight.data *= 0.001\n",
    "\n",
    "  def forward(self, users, items, values):\n",
    "\n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.item_bias(items)\n",
    "    d_bias = self.data_bias(values)\n",
    "\n",
    "    preds = u_bias + i_bias + d_bias\n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1_model = TwoLinear(n_user, n_item).to(device)\n",
    "weight1_optimizer = torch.optim.Adam(weight1_model.parameters(), \n",
    "                                     lr=base_model_args['learning_rate'],\n",
    "                                     weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2_model = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "weight2_optimizer = torch.optim.Adam(weight2_model.parameters(), \n",
    "                                     lr=weight2_model_args['learning_rate'],\n",
    "                                     weight_decay=weight2_model_args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_model = OneLinear(2).to(device)\n",
    "imputation_optimizer = torch.optim.Adam(imputation_model.parameters(),\n",
    "                                        lr=imputation_model_args['learning_rate'],\n",
    "                                        weight_decay=imputation_model_args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion\n",
    "sum_criterion = nn.MSELoss(reduction='sum')\n",
    "none_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15400, 1000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_args = Stop_args(patience=training_args['patience'], max_epochs=training_args['epochs'])\n",
    "early_stopping = EarlyStopping(base_model, **stopping_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_implicit import train_and_eval\n",
    "\n",
    "# setting that works well\n",
    "train_and_eval(train, \n",
    "               unif_train, \n",
    "               validation, \n",
    "               test,\n",
    "               device,\n",
    "               base_model_args = base_model_args, \n",
    "               weight1_model_args = weight1_model_args,\n",
    "               weight2_model_args = weight2_model_args,\n",
    "               imputation_model_args = imputation_model_args, \n",
    "               training_args = training_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
