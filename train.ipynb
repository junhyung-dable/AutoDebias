{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import *\n",
    "\n",
    "import arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.load_dataset\n",
    "import utils.data_loader\n",
    "import utils.metrics\n",
    "from utils.early_stop import EarlyStopping, Stop_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'yahooR3'\n",
    "base_model_args = {'emb_dim': 10, 'learning_rate': 0.01, 'imputaion_lambda': 0.01, 'weight_decay': 1}\n",
    "weight1_model_args ={'learning_rate': 0.1, 'weight_decay': 0.001}\n",
    "weight2_model_args =  {'learning_rate': 1e-3, 'weight_decay': 1e-2}\n",
    "imputation_model_args = {'learning_rate': 1e-1, 'weight_decay': 1e-4}\n",
    "training_args =  {'batch_size': 1024, 'epochs': 100, 'patience': 20, 'block_batch': [1000, 100]}\n",
    "uniform_ratio = 0.05\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_implicit import setup_seed\n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, unif_train, validation, test = utils.load_dataset.load_dataset(data_name=dataset, type='implicit', seed=seed, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indices: \n",
    "`When working with sparse tensors, the indices refer to the positions of non-zero elements in the tensor. It is a tensor of shape (N, D), where N represents the number of non-zero elements, and D corresponds to the number of dimensions or axes of the tensor. Each row in the indices tensor represents the coordinates of a non-zero element in the sparse tensor.`\n",
    "\n",
    "### Value:\n",
    "`The value refers to the actual non-zero values associated with the indices in a sparse tensor. It is a tensor of shape (N,), where N is the number of non-zero elements. Each element in the value tensor corresponds to the value of a non-zero element in the sparse tensor.`\n",
    "\n",
    "### nnz:\n",
    "`nnz stands for \"number of non-zero elements.\" It represents the count of non-zero elements present in a sparse tensor. In other words, it denotes the length of the indices and value tensors.`\n",
    "\n",
    "### Layout:\n",
    "`The layout of a sparse tensor defines how the indices and values are stored in memory. Torch supports different sparse tensor layouts, such as \"torch.sparse_coo\", \"torch.sparse_csr\", and \"torch.sparse_csc\". Each layout has its own advantages and is suited for specific operations and computations. For example, the \"torch.sparse_coo\" layout stores the indices and values as separate tensors, while the \"torch.sparse_csr\" and \"torch.sparse_csc\" layouts store them in a compressed format.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='yahooR3'\n",
    "training_args = {'batch_size': 1024, 'epochs': 500, 'patience': 60, 'block_batch': [6000, 500]}\n",
    "base_model_args = {'emb_dim': 10, 'learning_rate': 0.0001, 'imputaion_lambda': 1, 'weight_decay': 1}\n",
    "weight1_model_args = {'learning_rate': 0.01, 'weight_decay': 0.01}\n",
    "weight2_model_args = {'learning_rate': 1e-3, 'weight_decay': 1e-2}\n",
    "imputation_model_args = {'learning_rate': 1e-1, 'weight_decay': 1e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments.parse_args()\n",
    "# para(args)\n",
    "setup_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, unif_train, validation, test = utils.load_dataset.load_dataset(data_name=dataset, type = 'implicit', seed = seed, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / 500, Validation: MSE:0.442 NLL:-0.527 AUC:0.549\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain_implicit\u001b[39;00m \u001b[39mimport\u001b[39;00m train_and_eval\n\u001b[0;32m----> 3\u001b[0m train_and_eval(train, \n\u001b[1;32m      4\u001b[0m                unif_train, \n\u001b[1;32m      5\u001b[0m                validation, \n\u001b[1;32m      6\u001b[0m                test,\n\u001b[1;32m      7\u001b[0m                device,\n\u001b[1;32m      8\u001b[0m                base_model_args \u001b[39m=\u001b[39;49m base_model_args, \n\u001b[1;32m      9\u001b[0m                weight1_model_args \u001b[39m=\u001b[39;49m weight1_model_args,\n\u001b[1;32m     10\u001b[0m                weight2_model_args \u001b[39m=\u001b[39;49m weight2_model_args,\n\u001b[1;32m     11\u001b[0m                imputation_model_args \u001b[39m=\u001b[39;49m imputation_model_args, \n\u001b[1;32m     12\u001b[0m                training_args \u001b[39m=\u001b[39;49m training_args)\n",
      "File \u001b[0;32m~/AutoDebias/train_implicit.py:177\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(train_data, unif_train_data, val_data, test_data, device, base_model_args, weight1_model_args, weight2_model_args, imputation_model_args, training_args)\u001b[0m\n\u001b[1;32m    174\u001b[0m loss \u001b[39m=\u001b[39m loss_obs \u001b[39m+\u001b[39m base_model_args[\u001b[39m'\u001b[39m\u001b[39mimputaion_lambda\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m loss_all \u001b[39m+\u001b[39m base_model_args[\u001b[39m'\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m base_model\u001b[39m.\u001b[39ml2_norm(users_all, items_all)\n\u001b[1;32m    176\u001b[0m base_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 177\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    178\u001b[0m base_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    180\u001b[0m training_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train_implicit import train_and_eval\n",
    "\n",
    "train_and_eval(train, \n",
    "               unif_train, \n",
    "               validation, \n",
    "               test,\n",
    "               device,\n",
    "               base_model_args = base_model_args, \n",
    "               weight1_model_args = weight1_model_args,\n",
    "               weight2_model_args = weight2_model_args,\n",
    "               imputation_model_args = imputation_model_args, \n",
    "               training_args = training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 15399, 15399, 15399],\n",
       "                       [   13,   152,   169,  ...,   563,   636,   948]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "       size=(15400, 1000), nnz=125077, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train # print(unif_train._indices(), unif_train._values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400000 125077\n"
     ]
    }
   ],
   "source": [
    "# number of total and non-zero elements in the tensor\n",
    "print(train.coalesce().numel(), train.coalesce()._nnz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15400, 1000]) torch.Size([15400, 1000]) torch.Size([15400, 1000]) torch.Size([15400, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, unif_train.shape, validation.shape, test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_eval(train, \n",
    "#               unif_train,\n",
    "#               validation,\n",
    "#               test,\n",
    "#               device, \n",
    "#               base_model_args=base_model_args, \n",
    "#               weight1_model_args=weight1_model_args, \n",
    "#               weight2_model_args=weight2_model_args, \n",
    "#               imputation_model_args=imputation_model_args, \n",
    "#               training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform sparse to dense matrix\n",
    "train_data = train\n",
    "train_dense = train_data.to_dense()\n",
    "train_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif_train_data = unif_train\n",
    "users_unif = unif_train_data._indices()[0]\n",
    "items_unif = unif_train_data._indices()[1]\n",
    "y_unif = unif_train_data._values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data_loader. (block matrix data loader)\n",
    "\n",
    "train_loader = utils.data_loader.Block(train_data,\n",
    "                                       u_batch_size=training_args['block_batch'][0],\n",
    "                                       i_batch_size=training_args['block_batch'][1],\n",
    "                                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, test_data = validation, test\n",
    "val_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(val_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)\n",
    "test_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(test_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400 1000\n"
     ]
    }
   ],
   "source": [
    "# data shape\n",
    "n_user, n_item = train_data.shape\n",
    "print(n_user, n_item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "  \"\"\"\n",
    "  Base module for matrix factoriazation\n",
    "  \"\"\"\n",
    "  def __init__(self, n_user, n_item, dim=40, dropout=0, init=None):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_latent = nn.Embedding(n_user, dim)\n",
    "    self.item_latent = nn.Embedding(n_item, dim)\n",
    "    \n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "    \n",
    "    self.dropout_p = dropout\n",
    "    self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "    if not init:\n",
    "      self.init_embedding(init)\n",
    "    else:\n",
    "      self.init_embedding(0)\n",
    "    \n",
    "  def init_embedding(self, init):\n",
    "    nn.init.kaiming_normal_(self.user_latent.weight.data, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.item_latent.weight.data, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.user_bias.weight.data, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight.data, mode='fan_out', a=init)\n",
    "    \n",
    "  def forward(self, users, items):\n",
    "    u_latent = self.dropout(self.user_latent(users))\n",
    "    i_latent = self.dropout(self.item_latent(items))\n",
    "    \n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.user_bias(items)\n",
    "    \n",
    "    preds = torch.sum(u_latent * i_latent, dim=1, keepdim=True) + u_bias + i_bias\n",
    "    \n",
    "    return preds.squeeze(dim=-1)\n",
    "  \n",
    "  def l2_norm(self, users, items):\n",
    "    users = torch.unique(users)\n",
    "    items = torch.unique(items)\n",
    "    \n",
    "    l2_loss = (torch.sum(self.user_latent(users)**2) + torch.sum(self.item_latent(items)**2)) / 2\n",
    "    return l2_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MetaModule, MetaEmbed\n",
    "class MetaEmbed(MetaModule):\n",
    "  \"\"\"\n",
    "  Base module for matrix factorization\n",
    "  \"\"\"\n",
    "  def __init__(self, dim_1, dim_2):\n",
    "    super().__init__()\n",
    "    ignore = nn.Embedding(dim_1, dim_2)\n",
    "    \n",
    "    self.register_buffer('weight', to_var(ignore.weight.data, requires_grad=True))\n",
    "    self.register_buffer('bias', None)\n",
    "    \n",
    "  def forward(self):\n",
    "    return self.weight\n",
    "  \n",
    "  def named_leaves(self):\n",
    "    return [('weight', self.weight), ('bias', self.bias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaMF(MetaModule):\n",
    "    \"\"\"\n",
    "    Base module for matrix factorization.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_user, n_item, dim=40, dropout=0, init = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_latent = MetaEmbed(n_user, dim)\n",
    "        self.item_latent = MetaEmbed(n_item, dim)\n",
    "        self.user_bias = MetaEmbed(n_user, 1)\n",
    "        self.item_bias = MetaEmbed(n_item, 1)\n",
    "        self.dropout_p = dropout\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        if init is not None:\n",
    "            self.init_embedding(init)\n",
    "        else: \n",
    "            self.init_embedding(0)\n",
    "        \n",
    "    def init_embedding(self, init): \n",
    "\n",
    "        nn.init.kaiming_normal_(self.user_latent.weight, mode='fan_out', a = init)\n",
    "        nn.init.kaiming_normal_(self.item_latent.weight, mode='fan_out', a = init)\n",
    "        nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a = init)\n",
    "        nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a = init)\n",
    "          \n",
    "    def forward(self, users, items):\n",
    "        u_latent = self.dropout(self.user_latent.weight[users])\n",
    "        i_latent = self.dropout(self.item_latent.weight[items])\n",
    "        u_bias = self.user_bias.weight[users]\n",
    "        i_bias = self.item_bias.weight[items]\n",
    "\n",
    "        preds = torch.sum(u_latent * i_latent, dim=1, keepdim=True) + u_bias + i_bias\n",
    "        return preds.squeeze(dim=-1)\n",
    "\n",
    "    def l2_norm(self, users, items, unique = True): \n",
    "\n",
    "        users = torch.unique(users)\n",
    "        items = torch.unique(items)\n",
    "        \n",
    "        l2_loss = (torch.sum(self.user_latent.weight[users]**2) + torch.sum(self.item_latent.weight[items]**2)) / 2\n",
    "        return l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Define the embedding layer\n",
    "# embedding_dim = 10\n",
    "# vocab_size = 100\n",
    "# embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# # Example input indices\n",
    "# indices = torch.tensor(list(range(4)))\n",
    "\n",
    "# # Apply the embedding layer\n",
    "# embedded_output = embedding_layer(indices)\n",
    "\n",
    "# print(embedded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MetaMF(n_user, n_item, dim=base_model_args['emb_dim'], dropout=0).to(device)\n",
    "base_optimizer = torch.optim.SGD(base_model.params(), lr=base_model_args['learning_rate'], weight_decay=0) # todo: other optimizer SGD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "register_buffer 로 layer를 등록하면 어떤 특징이 있는가?\n",
    "\n",
    "1. optimizer가 업데이트하지 않는다.\n",
    "\n",
    "2. 그러나 값은 존재한다(하나의 layer로써 작용한다고 보면 된다.)\n",
    "\n",
    "3. state_dict()로 확인이 가능하다.\n",
    "\n",
    "4. GPU연산이 가능하다.\n",
    "\n",
    " \n",
    "\n",
    "따라서 네트워크를 구성함에 있어서 네트워크를 end2end로 학습시키고 싶은데 중간에 업데이트를 하지않는 일반 layer를 넣고 싶을 때 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x, requires_grad=True):\n",
    "  x = x.cuda() if torch.cuda.is_available() else x\n",
    "  return Variable(x, requires_grad=requires_grad) # 현재는 모든 tensor에서 required_grad 옵션을 통해 gradient를 추적할 수 있기 때문에 따로 위와 같이 Variable로 감싸줄 필요가 없다. (현재는 쓸 필요 없음)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLinear(nn.Module):\n",
    "  \"\"\"\n",
    "  linear model: r\n",
    "  \"\"\"\n",
    "  def __init__(self, n):\n",
    "    super().__init__()\n",
    "\n",
    "    self.bias = nn.Embedding(n,1)\n",
    "    self.init_embedding()\n",
    "\n",
    "  def init_embedding(self):\n",
    "    self.bias.weight.data *= 0.01\n",
    "\n",
    "  def forward(self, values):\n",
    "    d_bias = self.bias(values)\n",
    "    return d_bias.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLinear(nn.Module):\n",
    "  def __init__(self, n_user, n_item):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "\n",
    "    self.init_embedding(0)\n",
    "  \n",
    "  def init_embedding(self, init):\n",
    "    nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a=init)\n",
    "\n",
    "  def forward(self, users, items):\n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.item_bias(items)\n",
    "    preds = u_bias + i_bias\n",
    "    \n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLinear(nn.Module):\n",
    "  \"\"\"\n",
    "  linear model: u + i + r / o\n",
    "  \"\"\"\n",
    "  def __init__(self, n_user, n_item, n):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "    self.data_bias= nn.Embedding(n, 1)\n",
    "    self.init_embedding(0)\n",
    "      \n",
    "  def init_embedding(self, init): \n",
    "    nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.data_bias.weight, mode='fan_out', a = init)\n",
    "    self.data_bias.weight.data *= 0.001\n",
    "\n",
    "  def forward(self, users, items, values):\n",
    "\n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.item_bias(items)\n",
    "    d_bias = self.data_bias(values)\n",
    "\n",
    "    preds = u_bias + i_bias + d_bias\n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1_model = TwoLinear(n_user, n_item).to(device)\n",
    "weight1_optimizer = torch.optim.Adam(weight1_model.parameters(), \n",
    "                                     lr=base_model_args['learning_rate'],\n",
    "                                     weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2_model = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "weight2_optimizer = torch.optim.Adam(weight2_model.parameters(), \n",
    "                                     lr=weight2_model_args['learning_rate'],\n",
    "                                     weight_decay=weight2_model_args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_model = OneLinear(2).to(device)\n",
    "imputation_optimizer = torch.optim.Adam(imputation_model.parameters(),\n",
    "                                        lr=imputation_model_args['learning_rate'],\n",
    "                                        weight_decay=imputation_model_args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion\n",
    "sum_criterion = nn.MSELoss(reduction='sum')\n",
    "none_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15400, 1000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_args = Stop_args(patience=training_args['patience'], max_epochs=training_args['epochs'])\n",
    "early_stopping = EarlyStopping(base_model, **stopping_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / 500, Validation: MSE:0.442 NLL:-0.527 AUC:0.564\n",
      "Epoch:  1 / 500, Validation: MSE:0.305 NLL:-0.452 AUC:0.624\n",
      "Epoch:  2 / 500, Validation: MSE:0.292 NLL:-0.429 AUC:0.642\n",
      "Epoch:  3 / 500, Validation: MSE:0.292 NLL:-0.421 AUC:0.661\n",
      "Epoch:  4 / 500, Validation: MSE:0.293 NLL:-0.417 AUC:0.674\n",
      "Epoch:  5 / 500, Validation: MSE:0.293 NLL:-0.415 AUC:0.682\n",
      "Epoch:  6 / 500, Validation: MSE:0.293 NLL:-0.415 AUC:0.685\n",
      "Epoch:  7 / 500, Validation: MSE:0.293 NLL:-0.415 AUC:0.696\n",
      "Epoch:  8 / 500, Validation: MSE:0.292 NLL:-0.416 AUC:0.695\n",
      "Epoch:  9 / 500, Validation: MSE:0.291 NLL:-0.417 AUC:0.694\n",
      "Epoch: 10 / 500, Validation: MSE:0.291 NLL:-0.419 AUC:0.698\n",
      "Epoch: 11 / 500, Validation: MSE:0.290 NLL:-0.420 AUC:0.695\n",
      "Epoch: 12 / 500, Validation: MSE:0.289 NLL:-0.422 AUC:0.698\n",
      "Epoch: 13 / 500, Validation: MSE:0.289 NLL:-0.423 AUC:0.698\n",
      "Epoch: 14 / 500, Validation: MSE:0.289 NLL:-0.424 AUC:0.698\n",
      "Epoch: 15 / 500, Validation: MSE:0.289 NLL:-0.425 AUC:0.696\n",
      "Epoch: 16 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.698\n",
      "Epoch: 17 / 500, Validation: MSE:0.289 NLL:-0.426 AUC:0.700\n",
      "Epoch: 18 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 19 / 500, Validation: MSE:0.288 NLL:-0.427 AUC:0.700\n",
      "Epoch: 20 / 500, Validation: MSE:0.288 NLL:-0.427 AUC:0.701\n",
      "Epoch: 21 / 500, Validation: MSE:0.288 NLL:-0.427 AUC:0.701\n",
      "Epoch: 22 / 500, Validation: MSE:0.288 NLL:-0.427 AUC:0.702\n",
      "Epoch: 23 / 500, Validation: MSE:0.288 NLL:-0.427 AUC:0.703\n",
      "Epoch: 24 / 500, Validation: MSE:0.288 NLL:-0.427 AUC:0.704\n",
      "Epoch: 25 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.705\n",
      "Epoch: 26 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.703\n",
      "Epoch: 27 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 28 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.705\n",
      "Epoch: 29 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 30 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 31 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 32 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 33 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.701\n",
      "Epoch: 34 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.701\n",
      "Epoch: 35 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 36 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 37 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 38 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.701\n",
      "Epoch: 39 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.699\n",
      "Epoch: 40 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 41 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.699\n",
      "Epoch: 42 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 43 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.701\n",
      "Epoch: 44 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.699\n",
      "Epoch: 45 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.701\n",
      "Epoch: 46 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 47 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 48 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.700\n",
      "Epoch: 49 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 50 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 51 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 52 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.701\n",
      "Epoch: 53 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.703\n",
      "Epoch: 54 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 55 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 56 / 500, Validation: MSE:0.288 NLL:-0.426 AUC:0.702\n",
      "Epoch: 57 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.702\n",
      "Epoch: 58 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.701\n",
      "Epoch: 59 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.702\n",
      "Epoch: 60 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.702\n",
      "Epoch: 61 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.701\n",
      "Epoch: 62 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.702\n",
      "Epoch: 63 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.703\n",
      "Epoch: 64 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.703\n",
      "Epoch: 65 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.703\n",
      "Epoch: 66 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.704\n",
      "Epoch: 67 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.701\n",
      "Epoch: 68 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.702\n",
      "Epoch: 69 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.701\n",
      "Epoch: 70 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.700\n",
      "Epoch: 71 / 500, Validation: MSE:0.288 NLL:-0.425 AUC:0.702\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain_implicit\u001b[39;00m \u001b[39mimport\u001b[39;00m train_and_eval\n\u001b[1;32m      3\u001b[0m \u001b[39m# setting that works well\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_and_eval(train, \n\u001b[1;32m      5\u001b[0m                unif_train, \n\u001b[1;32m      6\u001b[0m                validation, \n\u001b[1;32m      7\u001b[0m                test,\n\u001b[1;32m      8\u001b[0m                device,\n\u001b[1;32m      9\u001b[0m                base_model_args \u001b[39m=\u001b[39;49m base_model_args, \n\u001b[1;32m     10\u001b[0m                weight1_model_args \u001b[39m=\u001b[39;49m weight1_model_args,\n\u001b[1;32m     11\u001b[0m                weight2_model_args \u001b[39m=\u001b[39;49m weight2_model_args,\n\u001b[1;32m     12\u001b[0m                imputation_model_args \u001b[39m=\u001b[39;49m imputation_model_args, \n\u001b[1;32m     13\u001b[0m                training_args \u001b[39m=\u001b[39;49m training_args)\n",
      "File \u001b[0;32m~/AutoDebias/train_implicit.py:144\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(train_data, unif_train_data, val_data, test_data, device, base_model_args, weight1_model_args, weight2_model_args, imputation_model_args, training_args)\u001b[0m\n\u001b[1;32m    142\u001b[0m weight2_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    143\u001b[0m imputation_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 144\u001b[0m loss_l\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m epo \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m20\u001b[39m:\n\u001b[1;32m    146\u001b[0m     weight1_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train_implicit import train_and_eval\n",
    "\n",
    "# setting that works well\n",
    "train_and_eval(train, \n",
    "               unif_train, \n",
    "               validation, \n",
    "               test,\n",
    "               device,\n",
    "               base_model_args = base_model_args, \n",
    "               weight1_model_args = weight1_model_args,\n",
    "               weight2_model_args = weight2_model_args,\n",
    "               imputation_model_args = imputation_model_args, \n",
    "               training_args = training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # users and items have shape of 1000 and 100, respectively\n",
    "# for epoch in range(training_args['epochs']):\n",
    "#   training_loss = 0\n",
    "#   for u_batch_idx, users in enumerate(train_loader.User_loader):\n",
    "#     for i_batch_idx, items in enumerate(train_loader.Item_loader):\n",
    "#       # training set: 1. update parameters one_step (assumed update); 2. update parameters (real update) \n",
    "#       # uniform set: update hyper_parameters using gradient descent.\n",
    "      \n",
    "#       # print(users.shape, items.shape) # torch.Size([1000]) torch.Size([100])\n",
    "      \n",
    "#       # index_row = np.isin(train_data._indices()[0].cpu().numpy(), users.cpu().numpy())\n",
    "#       # index_col = np.isin(train_data._indices()[1].cpu().numpy(), items.cpu().numpy())\n",
    "#       # index = torch.tensor(np.where(index_row * index_col)[0]).to(device)\n",
    "#       # print(index_row.shape, index_col.shape, index.shape) # (125077,) (125077,) <- number of observed elements / torch.Size([1023])\n",
    "      \n",
    "#       # y_train consists of 1s only\n",
    "#       users_train, items_train, y_train = train_loader.get_batch(users, items, device)\n",
    "#       # print(users_train.shape, items_train.shape) # ex. torch.Size([1023]) torch.Size([1023])\n",
    "    \n",
    "#       # calculate weight 1\n",
    "#       weight1_model.train()\n",
    "#       weight1 = weight1_model(users_train, items_train)\n",
    "#       weight1 = torch.exp(weight1/5)\n",
    "      \n",
    "#       # all pair\n",
    "#       all_pair = torch.cartesian_prod(users, items)\n",
    "#       users_all, items_all = all_pair[:, 0], all_pair[:, 1]\n",
    "#       # print(users_all.shape) # torch.Size([1000 * 100])\n",
    "      \n",
    "#       # calculate weight 2\n",
    "#       weight2_model.train()\n",
    "#       weight2 = weight2_model(users_all, items_all, (train_dense[users_all,items_all]!=0)*1) # *1: bool -> int\n",
    "#       weight2 = torch.exp(weight2/5)\n",
    "      \n",
    "#       # caclculate imputation values\n",
    "#       imputation_model.train()\n",
    "#       impu_f_all = torch.tanh(imputation_model((train_dense[users_all,items_all]).long()))\n",
    "      \n",
    "#       # print(weight1.shape, weight2.shape, impu_f_all.shape) # torch.Size([788]) torch.Size([100000]) torch.Size([100000])\n",
    "      \n",
    "#       ######################################\n",
    "#       ## 1. Assumed Update of theta (Black Arrows) #\n",
    "#       ######################################\n",
    "#       # one_step_model: assumed model, just update one step on base model. it is for updating weight parameters\n",
    "#       one_step_model = MetaMF(n_user, n_item, dim=base_model_args['emb_dim'], dropout=0)\n",
    "#       one_step_model.load_state_dict(base_model.state_dict()) # state_dict 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체\n",
    "      \n",
    "#       # formal parameter: using training set to update parameters\n",
    "#       one_step_model.train()\n",
    "#       # all pair data in this block\n",
    "#       y_hat_f_all = one_step_model(users_all, items_all)\n",
    "#       cost_f_all = none_criterion(y_hat_f_all, impu_f_all)\n",
    "#       loss_f_all = torch.sum(cost_f_all * weight2)\n",
    "\n",
    "#       # observation data\n",
    "#       y_hat_f_obs = one_step_model(users_train, items_train)\n",
    "#       cost_f_obs = none_criterion(y_hat_f_obs, y_train)\n",
    "#       loss_f_obs = torch.sum(cost_f_obs * weight1)\n",
    "#       loss_f = loss_f_obs + base_model_args['imputaion_lambda'] * loss_f_all + base_model_args['weight_decay'] * one_step_model.l2_norm(users_all, items_all)\n",
    "      \n",
    "#       # assumed update (not a real update)\n",
    "#       one_step_model.zero_grad()\n",
    "#       grads = torch.autograd.grad(loss_f, (one_step_model.params()), create_graph=True)\n",
    "#       one_step_model.update_params(base_model_args['learning_rate'], source_params=grads)\n",
    "      \n",
    "#       ######################################\n",
    "#       ### 2. Update of pi (Blue Arrows) ####\n",
    "#       ######################################\n",
    "#       # latter hyper_parameter: Using uniform set to update hyper_parameters\n",
    "#       y_hat_l = one_step_model(users_unif, items_unif)\n",
    "#       loss_l = sum_criterion(y_hat_l, y_unif)\n",
    "      \n",
    "#       # update hyper-parameters\n",
    "#       weight1_optimizer.zero_grad()\n",
    "#       weight2_optimizer.zero_grad()\n",
    "#       imputation_optimizer.zero_grad()\n",
    "#       loss_l.backward()\n",
    "#       if epoch >= 20:\n",
    "#         weight1_optimizer.step()\n",
    "#         weight2_optimizer.step()\n",
    "#       imputation_optimizer.step()\n",
    "      \n",
    "      \n",
    "#       ######################################\n",
    "#       ### 3. Update of theta (Black Arrows) ####\n",
    "#       ######################################\n",
    "#       # use new weights to update parameters (real update)\n",
    "#       weight1_model.train()\n",
    "#       weight1 = weight1_model(users_train, items_train)\n",
    "#       weight1 = torch.exp(weight1/5)\n",
    "      \n",
    "#       # calculate weight2\n",
    "#       weight2_model.train()\n",
    "#       weight2 = weight2_model(users_all, items_all,(train_dense[users_all,items_all]!=0)*1)\n",
    "#       weight2 = torch.exp(weight2/5) # for stable training\n",
    "      \n",
    "#       # use new imputation to update parameters\n",
    "#       imputation_model.train()\n",
    "#       impu_all = torch.tanh(imputation_model((train_dense[users_all,items_all]).long()))\n",
    "\n",
    "#       # loss of training set\n",
    "#       base_model.train()\n",
    "#       # all pair\n",
    "#       y_hat_all = base_model(users_all, items_all)\n",
    "#       cost_all = none_criterion(y_hat_all, impu_all)\n",
    "#       loss_all = torch.sum(cost_all * weight2)\n",
    "#       # observation\n",
    "#       y_hat_obs = base_model(users_train, items_train)\n",
    "#       cost_obs = none_criterion(y_hat_obs, y_train)\n",
    "#       loss_obs = torch.sum(cost_obs * weight1)\n",
    "#       loss = loss_obs + base_model_args['imputaion_lambda'] * loss_all + base_model_args['weight_decay'] * base_model.l2_norm(users_all, items_all)\n",
    "      \n",
    "#       base_optimizer.zero_grad()\n",
    "#       loss.backward()\n",
    "#       base_optimizer.step()\n",
    "\n",
    "#       training_loss += loss.item()\n",
    "      \n",
    "#   base_model.eval()\n",
    "#   with torch.no_grad():\n",
    "#       # training metrics\n",
    "#       train_pre_ratings = torch.empty(0).to(device)\n",
    "#       train_ratings = torch.empty(0).to(device)\n",
    "#       for u_batch_idx, users in enumerate(train_loader.User_loader): \n",
    "#           for i_batch_idx, items in enumerate(train_loader.Item_loader): \n",
    "#               users_train, items_train, y_train = train_loader.get_batch(users, items, device)\n",
    "#               pre_ratings = base_model(users_train, items_train)\n",
    "#               train_pre_ratings = torch.cat((train_pre_ratings, pre_ratings))\n",
    "#               train_ratings = torch.cat((train_ratings, y_train))\n",
    "\n",
    "#       # validation metrics\n",
    "#       val_pre_ratings = torch.empty(0).to(device)\n",
    "#       val_ratings = torch.empty(0).to(device)\n",
    "#       for batch_idx, (users, items, ratings) in enumerate(val_loader):\n",
    "#           pre_ratings = base_model(users, items)\n",
    "#           val_pre_ratings = torch.cat((val_pre_ratings, pre_ratings))\n",
    "#           val_ratings = torch.cat((val_ratings, ratings))\n",
    "\n",
    "#   train_results = utils.metrics.evaluate(train_pre_ratings, train_ratings, ['MSE'], device)\n",
    "#   val_results = utils.metrics.evaluate(val_pre_ratings, val_ratings, ['MSE', 'NLL', 'AUC'], device)\n",
    "\n",
    "#   print('Epoch: {0:2d} / {1}, Validation: {2}'.\n",
    "#           format(epoch, training_args['epochs'], \n",
    "#               ' '.join([key+':'+'%.3f'%val_results[key] for key in val_results])))\n",
    "\n",
    "#   if epoch >= 50 and early_stopping.check([val_results['AUC']], epoch):\n",
    "#       break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. IPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.IPS import train_and_eval as train_and_eval_ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / 500, Traning: MSE:0.778 NLL:-0.633, Validation: MSE:1.047 NLL:-0.704 AUC:0.570\n",
      "Epoch:  1 / 500, Traning: MSE:0.648 NLL:-0.593, Validation: MSE:1.089 NLL:-0.714 AUC:0.592\n",
      "Epoch:  2 / 500, Traning: MSE:0.564 NLL:-0.565, Validation: MSE:1.129 NLL:-0.723 AUC:0.604\n",
      "Epoch:  3 / 500, Traning: MSE:0.503 NLL:-0.543, Validation: MSE:1.167 NLL:-0.731 AUC:0.612\n",
      "Epoch:  4 / 500, Traning: MSE:0.457 NLL:-0.525, Validation: MSE:1.203 NLL:-0.740 AUC:0.617\n",
      "Epoch:  5 / 500, Traning: MSE:0.420 NLL:-0.511, Validation: MSE:1.238 NLL:-0.747 AUC:0.621\n",
      "Epoch:  6 / 500, Traning: MSE:0.389 NLL:-0.498, Validation: MSE:1.271 NLL:-0.754 AUC:0.623\n",
      "Epoch:  7 / 500, Traning: MSE:0.363 NLL:-0.488, Validation: MSE:1.302 NLL:-0.761 AUC:0.625\n",
      "Epoch:  8 / 500, Traning: MSE:0.340 NLL:-0.479, Validation: MSE:1.333 NLL:-0.768 AUC:0.626\n",
      "Epoch:  9 / 500, Traning: MSE:0.320 NLL:-0.471, Validation: MSE:1.362 NLL:-0.774 AUC:0.627\n",
      "Epoch: 10 / 500, Traning: MSE:0.302 NLL:-0.464, Validation: MSE:1.391 NLL:-0.781 AUC:0.628\n",
      "Epoch: 11 / 500, Traning: MSE:0.286 NLL:-0.457, Validation: MSE:1.418 NLL:-0.786 AUC:0.628\n",
      "Epoch: 12 / 500, Traning: MSE:0.271 NLL:-0.451, Validation: MSE:1.445 NLL:-0.792 AUC:0.628\n",
      "Epoch: 13 / 500, Traning: MSE:0.258 NLL:-0.446, Validation: MSE:1.470 NLL:-0.798 AUC:0.629\n",
      "Epoch: 14 / 500, Traning: MSE:0.246 NLL:-0.441, Validation: MSE:1.495 NLL:-0.803 AUC:0.629\n",
      "Epoch: 15 / 500, Traning: MSE:0.234 NLL:-0.436, Validation: MSE:1.520 NLL:-0.808 AUC:0.629\n",
      "Epoch: 16 / 500, Traning: MSE:0.224 NLL:-0.432, Validation: MSE:1.543 NLL:-0.813 AUC:0.629\n",
      "Epoch: 17 / 500, Traning: MSE:0.214 NLL:-0.428, Validation: MSE:1.566 NLL:-0.818 AUC:0.629\n",
      "Epoch: 18 / 500, Traning: MSE:0.205 NLL:-0.424, Validation: MSE:1.589 NLL:-0.823 AUC:0.630\n",
      "Epoch: 19 / 500, Traning: MSE:0.197 NLL:-0.420, Validation: MSE:1.611 NLL:-0.828 AUC:0.630\n",
      "Epoch: 20 / 500, Traning: MSE:0.189 NLL:-0.417, Validation: MSE:1.632 NLL:-0.832 AUC:0.630\n",
      "Epoch: 21 / 500, Traning: MSE:0.182 NLL:-0.414, Validation: MSE:1.653 NLL:-0.836 AUC:0.630\n",
      "Epoch: 22 / 500, Traning: MSE:0.175 NLL:-0.411, Validation: MSE:1.674 NLL:-0.841 AUC:0.630\n",
      "Epoch: 23 / 500, Traning: MSE:0.169 NLL:-0.408, Validation: MSE:1.694 NLL:-0.845 AUC:0.630\n",
      "Epoch: 24 / 500, Traning: MSE:0.163 NLL:-0.405, Validation: MSE:1.713 NLL:-0.849 AUC:0.630\n",
      "Epoch: 25 / 500, Traning: MSE:0.157 NLL:-0.403, Validation: MSE:1.733 NLL:-0.853 AUC:0.630\n",
      "Epoch: 26 / 500, Traning: MSE:0.152 NLL:-0.401, Validation: MSE:1.751 NLL:-0.857 AUC:0.630\n",
      "Epoch: 27 / 500, Traning: MSE:0.147 NLL:-0.398, Validation: MSE:1.770 NLL:-0.861 AUC:0.630\n",
      "Epoch: 28 / 500, Traning: MSE:0.142 NLL:-0.396, Validation: MSE:1.788 NLL:-0.865 AUC:0.630\n",
      "Epoch: 29 / 500, Traning: MSE:0.137 NLL:-0.394, Validation: MSE:1.805 NLL:-0.868 AUC:0.630\n",
      "Epoch: 30 / 500, Traning: MSE:0.133 NLL:-0.392, Validation: MSE:1.823 NLL:-0.872 AUC:0.630\n",
      "Epoch: 31 / 500, Traning: MSE:0.129 NLL:-0.390, Validation: MSE:1.839 NLL:-0.875 AUC:0.630\n",
      "Epoch: 32 / 500, Traning: MSE:0.125 NLL:-0.388, Validation: MSE:1.856 NLL:-0.879 AUC:0.630\n",
      "Epoch: 33 / 500, Traning: MSE:0.121 NLL:-0.386, Validation: MSE:1.872 NLL:-0.882 AUC:0.630\n",
      "Epoch: 34 / 500, Traning: MSE:0.118 NLL:-0.385, Validation: MSE:1.888 NLL:-0.885 AUC:0.630\n",
      "Epoch: 35 / 500, Traning: MSE:0.115 NLL:-0.383, Validation: MSE:1.904 NLL:-0.889 AUC:0.630\n",
      "Epoch: 36 / 500, Traning: MSE:0.111 NLL:-0.381, Validation: MSE:1.920 NLL:-0.892 AUC:0.630\n",
      "Epoch: 37 / 500, Traning: MSE:0.108 NLL:-0.380, Validation: MSE:1.935 NLL:-0.895 AUC:0.630\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m ips_training_args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1024\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m500\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpatience\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m60\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblock_batch\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m6000\u001b[39m, \u001b[39m500\u001b[39m]}\n\u001b[1;32m      2\u001b[0m ips_base_model_args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39memb_dim\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.00001\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m}\n\u001b[0;32m----> 4\u001b[0m train_and_eval_ips(train_data,\n\u001b[1;32m      5\u001b[0m                    unif_train_data,\n\u001b[1;32m      6\u001b[0m                    val_data,\n\u001b[1;32m      7\u001b[0m                    test_data,\n\u001b[1;32m      8\u001b[0m                    device \u001b[39m=\u001b[39;49m device, \n\u001b[1;32m      9\u001b[0m                    model_args \u001b[39m=\u001b[39;49m ips_base_model_args,\n\u001b[1;32m     10\u001b[0m                    training_args \u001b[39m=\u001b[39;49m  ips_training_args)\n",
      "File \u001b[0;32m~/AutoDebias/baselines/IPS.py:107\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(train_data, unif_train_data, val_data, test_data, device, model_args, training_args)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m u_batch_idx, users \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader\u001b[39m.\u001b[39mUser_loader): \n\u001b[1;32m    106\u001b[0m     \u001b[39mfor\u001b[39;00m i_batch_idx, items \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader\u001b[39m.\u001b[39mItem_loader): \n\u001b[0;32m--> 107\u001b[0m         users_train, items_train, y_train \u001b[39m=\u001b[39m train_loader\u001b[39m.\u001b[39;49mget_batch(users, items, device)\n\u001b[1;32m    108\u001b[0m         pre_ratings \u001b[39m=\u001b[39m model(users_train, items_train)\n\u001b[1;32m    109\u001b[0m         train_pre_ratings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((train_pre_ratings, pre_ratings))\n",
      "File \u001b[0;32m~/AutoDebias/utils/data_loader.py:26\u001b[0m, in \u001b[0;36mBlock.get_batch\u001b[0;34m(self, batch_user, batch_item, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_batch\u001b[39m(\u001b[39mself\u001b[39m, batch_user, batch_item, device \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m): \n\u001b[0;32m---> 26\u001b[0m     index_row \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49misin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmat\u001b[39m.\u001b[39;49m_indices()[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy(), batch_user\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy())\n\u001b[1;32m     27\u001b[0m     index_col \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmat\u001b[39m.\u001b[39m_indices()[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), batch_item\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     28\u001b[0m     index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mwhere(index_row \u001b[39m*\u001b[39m index_col)[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:739\u001b[0m, in \u001b[0;36misin\u001b[0;34m(element, test_elements, assume_unique, invert)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[39mCalculates ``element in test_elements``, broadcasting over `element` only.\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[39mReturns a boolean array of the same shape as `element` that is True\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[39m       [ True, False]])\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    738\u001b[0m element \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(element)\n\u001b[0;32m--> 739\u001b[0m \u001b[39mreturn\u001b[39;00m in1d(element, test_elements, assume_unique\u001b[39m=\u001b[39;49massume_unique,\n\u001b[1;32m    740\u001b[0m             invert\u001b[39m=\u001b[39;49minvert)\u001b[39m.\u001b[39mreshape(element\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36min1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:618\u001b[0m, in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m assume_unique:\n\u001b[1;32m    617\u001b[0m     ar1, rev_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(ar1, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 618\u001b[0m     ar2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(ar2)\n\u001b[1;32m    620\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((ar1, ar2))\n\u001b[1;32m    621\u001b[0m \u001b[39m# We need this to be a stable sort, so always use 'mergesort'\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m# here. The values from the first array should always come before\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39m# the values from the second array.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ips_training_args = {'batch_size': 1024, 'epochs': 500, 'patience': 60, 'block_batch': [6000, 500]}\n",
    "ips_base_model_args = {'emb_dim': 10, 'learning_rate': 0.00001, 'weight_decay': 0}\n",
    "\n",
    "train_and_eval_ips(train_data,\n",
    "                   unif_train_data,\n",
    "                   val_data,\n",
    "                   test_data,\n",
    "                   device=device, \n",
    "                   model_args=ips_base_model_args,\n",
    "                   training_args=ips_training_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
