{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import *\n",
    "\n",
    "import arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.load_dataset\n",
    "import utils.data_loader\n",
    "import utils.metrics\n",
    "from utils.early_stop import EarlyStopping, Stop_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'yahooR3'\n",
    "base_model_args = {'emb_dim': 10, 'learning_rate': 0.01, 'imputaion_lambda': 0.01, 'weight_decay': 1}\n",
    "weight1_model_args ={'learning_rate': 0.1, 'weight_decay': 0.001}\n",
    "weight2_model_args =  {'learning_rate': 1e-3, 'weight_decay': 1e-2}\n",
    "imputation_model_args = {'learning_rate': 1e-1, 'weight_decay': 1e-4}\n",
    "training_args =  {'batch_size': 1024, 'epochs': 100, 'patience': 20, 'block_batch': [1000, 100]}\n",
    "uniform_ratio = 0.05\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_implicit import setup_seed\n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, unif_train, validation, test = utils.load_dataset.load_dataset(data_name=dataset, type='implicit', seed=seed, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indices: \n",
    "`When working with sparse tensors, the indices refer to the positions of non-zero elements in the tensor. It is a tensor of shape (N, D), where N represents the number of non-zero elements, and D corresponds to the number of dimensions or axes of the tensor. Each row in the indices tensor represents the coordinates of a non-zero element in the sparse tensor.`\n",
    "\n",
    "### Value:\n",
    "`The value refers to the actual non-zero values associated with the indices in a sparse tensor. It is a tensor of shape (N,), where N is the number of non-zero elements. Each element in the value tensor corresponds to the value of a non-zero element in the sparse tensor.`\n",
    "\n",
    "### nnz:\n",
    "`nnz stands for \"number of non-zero elements.\" It represents the count of non-zero elements present in a sparse tensor. In other words, it denotes the length of the indices and value tensors.`\n",
    "\n",
    "### Layout:\n",
    "`The layout of a sparse tensor defines how the indices and values are stored in memory. Torch supports different sparse tensor layouts, such as \"torch.sparse_coo\", \"torch.sparse_csr\", and \"torch.sparse_csc\". Each layout has its own advantages and is suited for specific operations and computations. For example, the \"torch.sparse_coo\" layout stores the indices and values as separate tensors, while the \"torch.sparse_csr\" and \"torch.sparse_csc\" layouts store them in a compressed format.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 15399, 15399, 15399],\n",
       "                       [   13,   152,   169,  ...,   563,   636,   948]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "       size=(15400, 1000), nnz=125077, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train # print(unif_train._indices(), unif_train._values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400000 125077\n"
     ]
    }
   ],
   "source": [
    "# number of total and non-zero elements in the tensor\n",
    "print(train.coalesce().numel(), train.coalesce()._nnz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15400, 1000]) torch.Size([15400, 1000]) torch.Size([15400, 1000]) torch.Size([15400, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, unif_train.shape, validation.shape, test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_eval(train, \n",
    "#               unif_train,\n",
    "#               validation,\n",
    "#               test,\n",
    "#               device, \n",
    "#               base_model_args=base_model_args, \n",
    "#               weight1_model_args=weight1_model_args, \n",
    "#               weight2_model_args=weight2_model_args, \n",
    "#               imputation_model_args=imputation_model_args, \n",
    "#               training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform sparse to dense matrix\n",
    "train_data = train\n",
    "train_dense = train_data.to_dense()\n",
    "train_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif_train_data = unif_train\n",
    "users_unif = unif_train_data._indices()[0]\n",
    "items_unif = unif_train_data._indices()[1]\n",
    "y_unif = unif_train_data._values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data_loader. (block matrix data loader)\n",
    "\n",
    "train_loader = utils.data_loader.Block(train_data,\n",
    "                                       u_batch_size=training_args['block_batch'][0],\n",
    "                                       i_batch_size=training_args['block_batch'][1],\n",
    "                                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, test_data = validation, test\n",
    "val_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(val_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)\n",
    "test_loader = utils.data_loader.DataLoader(utils.data_loader.Interactions(test_data), batch_size=training_args['batch_size'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400 1000\n"
     ]
    }
   ],
   "source": [
    "# data shape\n",
    "n_user, n_item = train_data.shape\n",
    "print(n_user, n_item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MF(nn.Module):\n",
    "#   \"\"\"\n",
    "#   Base module for matrix factoriazation\n",
    "#   \"\"\"\n",
    "#   def __init__(self, n_user, n_item, dim=40, dropout=0, init=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "register_buffer 로 layer를 등록하면 어떤 특징이 있는가?\n",
    "\n",
    "1. optimizer가 업데이트하지 않는다.\n",
    "\n",
    "2. 그러나 값은 존재한다(하나의 layer로써 작용한다고 보면 된다.)\n",
    "\n",
    "3. state_dict()로 확인이 가능하다.\n",
    "\n",
    "4. GPU연산이 가능하다.\n",
    "\n",
    " \n",
    "\n",
    "따라서 네트워크를 구성함에 있어서 네트워크를 end2end로 학습시키고 싶은데 중간에 업데이트를 하지않는 일반 layer를 넣고 싶을 때 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x, requires_grad=True):\n",
    "  if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "  return Variable(x, requires_grad=requires_grad) # 현재는 모든 tensor에서 required_grad 옵션을 통해 gradient를 추적할 수 있기 때문에 따로 위와 같이 Variable로 감싸줄 필요가 없다. (현재는 쓸 필요 없음)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MetaModule, MetaEmbed\n",
    "class MetaEmbed(MetaModule):\n",
    "  \"\"\"\n",
    "  Base module for matrix factorization\n",
    "  \"\"\"\n",
    "  def __init__(self, dim_1, dim_2):\n",
    "    super().__init__()\n",
    "    ignore = nn.Embedding(dim_1, dim_2)\n",
    "    \n",
    "    self.register_buffer('weight', to_var(ignore.weight.data, requires_grad=True))\n",
    "    self.register_buffer('bias', None)\n",
    "    \n",
    "  def forward(self):\n",
    "    return self.weight\n",
    "  \n",
    "  def named_leaves(self):\n",
    "    return [('weight', self.weight), ('bias', self.bias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MetaMF(MetaModule):\n",
    "#   \"\"\" \n",
    "#   Base module for matrix factorization\n",
    "#   \"\"\"\n",
    "  \n",
    "#   def __init__(self, n_user, n_item, dim=40, dropout=0, init=None):\n",
    "#     super().__init__()\n",
    "    \n",
    "#     self.user_latent = MetaEmbed(n_user, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLinear(nn.Module):\n",
    "  \"\"\"\n",
    "  linear model: r\n",
    "  \"\"\"\n",
    "  def __init__(self, n):\n",
    "    super().__init__()\n",
    "\n",
    "    self.bias = nn.Embedding(n,1)\n",
    "    self.init_embedding()\n",
    "\n",
    "  def init_embedding(self):\n",
    "    self.bias.weight.data *= 0.01\n",
    "\n",
    "  def forward(self, values):\n",
    "    d_bias = self.bias(values)\n",
    "    return d_bias.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLinear(nn.Module):\n",
    "  def __init__(self, n_user, n_item):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "\n",
    "    self.init_embedding(0)\n",
    "  \n",
    "  def init_embedding(self, init):\n",
    "    nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a=init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a=init)\n",
    "\n",
    "  def forward(self, users, items):\n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.item_bias(items)\n",
    "    preds = u_bias + i_bias\n",
    "    \n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLinear(nn.Module):\n",
    "  \"\"\"\n",
    "  linear model: u + i + r / o\n",
    "  \"\"\"\n",
    "  def __init__(self, n_user, n_item, n):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_bias = nn.Embedding(n_user, 1)\n",
    "    self.item_bias = nn.Embedding(n_item, 1)\n",
    "    self.data_bias= nn.Embedding(n, 1)\n",
    "    self.init_embedding(0)\n",
    "      \n",
    "  def init_embedding(self, init): \n",
    "    nn.init.kaiming_normal_(self.user_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.item_bias.weight, mode='fan_out', a = init)\n",
    "    nn.init.kaiming_normal_(self.data_bias.weight, mode='fan_out', a = init)\n",
    "    self.data_bias.weight.data *= 0.001\n",
    "\n",
    "  def forward(self, users, items, values):\n",
    "\n",
    "    u_bias = self.user_bias(users)\n",
    "    i_bias = self.item_bias(items)\n",
    "    d_bias = self.data_bias(values)\n",
    "\n",
    "    preds = u_bias + i_bias + d_bias\n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1_model = TwoLinear(n_user, n_item).to(device)\n",
    "weight1_optimizer = torch.optim.Adam(weight1_model.parameters(), \n",
    "                                     lr=base_model_args['learning_rate'],\n",
    "                                     weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2_model = ThreeLinear(n_user, n_item, 2).to(device)\n",
    "weight2_optimizer = torch.optim.Adam(weight2_model.parameters(), lr=weight2_model_args['learning_rate'], weight_decay=weight2_model_args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_model = OneLinear(2).to(device)\n",
    "imputation_optimizer = torch.optim.Adam(imputation_model.parameters(), lr=imputation_model_args['learning_rate'], weight_decay=imputation_model_args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion\n",
    "sum_criterion = nn.MSELoss(reduction='sum')\n",
    "none_criterion = nn.MSELoss(reduction='none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
